{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399fe49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.utils import prune\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "plt.rcParams['font.family'] = 'Bookman Old Style'\n",
    "\n",
    "\n",
    "class dataset:\n",
    "    def __init__(self, x, y, num_training_points=5000, num_memory_levels =3):\n",
    "        self.num_training_points = num_training_points\n",
    "        self.num_memory_levels = num_memory_levels # If there are 0 memory taps, this is 1\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "        self.model_training_input, self.model_training_output, self.training_phase, self.model_valid_input, self.model_valid_output, self.valid_phase = self.prepare_data()\n",
    "\n",
    "    def phase_vector(self, x):    \n",
    "        \"\"\"Takes a vector x and returns a vector of phases of each element\"\"\"\n",
    "        Ax = np.abs(x)\n",
    "        return np.conj(x)/Ax\n",
    "\n",
    "    def model_expected_output(self, y, phase):\n",
    "        \"\"\"Take in data, phase normalised it, and trim. Return as IQ seperately\"\"\"\n",
    "        y_denorm = y*phase\n",
    "        y_denorm_trim = y_denorm[self.num_memory_levels:]\n",
    "        return np.array([np.real(y_denorm_trim), np.imag(y_denorm_trim)]).T\n",
    "\n",
    "    def build_xfc(self, x, num_memory_levels):\n",
    "        \"\"\"\n",
    "        Replicates the MATLAB build_xfc() function.\n",
    "        \"\"\"\n",
    "        num_points = len(x)\n",
    "        phase = self.phase_vector(x)\n",
    "        I = np.real(x)\n",
    "        Q = np.imag(x)\n",
    "\n",
    "        # Phase-normalized data\n",
    "        phase_norm_data = np.zeros((num_points, num_memory_levels), dtype=complex)\n",
    "        for n in range(num_memory_levels, num_points):\n",
    "            for m in range(num_memory_levels):\n",
    "                phase_norm_data[n, m] = x[n - m - 1] * phase[n]\n",
    "\n",
    "        # Ax magnitude feature\n",
    "        Ax = np.sqrt(I**2 + Q**2)\n",
    "\n",
    "        # Build A feature matrix (Ax memory taps)\n",
    "        A_feats = np.zeros((num_points, num_memory_levels))\n",
    "        for n in range(num_memory_levels, num_points):\n",
    "            for m in range(num_memory_levels):\n",
    "                A_feats[n, m] = Ax[n - m]\n",
    "\n",
    "        # Trim first num_memory_levels samples (as in MATLAB)\n",
    "        phase_norm_data = phase_norm_data[num_memory_levels:, :]\n",
    "        A_feats = A_feats[num_memory_levels:, :]\n",
    "        A3_feats = A_feats ** 3\n",
    "\n",
    "        # Combine real and imaginary phase-normalized parts with A-features\n",
    "        xfc = np.hstack([\n",
    "            np.real(phase_norm_data),\n",
    "            np.imag(phase_norm_data),\n",
    "            A_feats,\n",
    "            A3_feats\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        return xfc\n",
    "\n",
    "    def build_x_matrix(self, x, num_mem_levels, num_nl_orders):\n",
    "        \"\"\"Build Matrix X for find Volterra Model\"\"\"\n",
    "        num_points = len(x)\n",
    "        X = np.zeros((num_points, num_mem_levels * num_nl_orders), dtype=np.complex128)\n",
    "        \n",
    "        for n in range(num_mem_levels - 1, num_points):\n",
    "            col = 0\n",
    "            for i in range(num_mem_levels):\n",
    "                xi = x[n - i]\n",
    "                for j in range(num_nl_orders):\n",
    "                    X[n, col] = (abs(xi) ** ((j) * 2)) * xi\n",
    "                    col += 1\n",
    "\n",
    "        return X\n",
    "\n",
    "    def build_y(self, u, A, num_mem_levels, num_nl_orders):\n",
    "        \"\"\"Builds y, the output of the volterra Model. Trims Output\"\"\"\n",
    "        num_points = len(u)\n",
    "        y = np.zeros((num_points, 1), dtype=np.complex128)\n",
    "        for n in range(num_mem_levels - 1, num_points):\n",
    "            col = 0 \n",
    "            for i in range(num_mem_levels):\n",
    "                ui = u[n-i]\n",
    "                for j in range(num_nl_orders):\n",
    "                    y[n]= y[n] + A[col]*(abs(ui)**(j*2)*ui)\n",
    "                    col += 1\n",
    "        y = y[self.num_memory_levels:]\n",
    "        return y\n",
    "            \n",
    "\n",
    "    def volterra(self,num_nl_orders):\n",
    "        \"\"\"Build component matrix A\"\"\"\n",
    "        X = self.build_x_matrix(self.model_training_input, self.num_memory_levels, num_nl_orders)\n",
    "        \n",
    "        X_trim = X[self.num_memory_levels:, :]\n",
    "        y_trim = self.model_training_output[self.num_memory_levels:]\n",
    "        return np.linalg.pinv(X_trim.conj().T @ X_trim) @ (X_trim.conj().T @ y_trim);\n",
    "\n",
    "    def training_data(self):\n",
    "        \"\"\"Assign some data for just training\"\"\"\n",
    "        idx_training = range(0, self.num_training_points -1) # training indices\n",
    "\n",
    "        model_training_input = self.y[idx_training]\n",
    "        model_training_output = self.x[idx_training]\n",
    "        return model_training_input, model_training_output\n",
    "    \n",
    "\n",
    "    def validation_data(self):\n",
    "        \"\"\"Assign some data for just validation\"\"\"\n",
    "        num_validation_points = self.num_training_points \n",
    "        validation_end_index = self.num_training_points + num_validation_points\n",
    "        idx_validation = range(self.num_training_points, validation_end_index -1) # validation indices\n",
    "        model_valid_input = self.y[idx_validation]\n",
    "        model_valid_output = self.x[idx_validation]\n",
    "        return model_valid_input, model_valid_output\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare training and validation data sets\"\"\"\n",
    "        # Training Data\n",
    "        model_training_input, model_training_output = self.training_data()\n",
    "        training_phase = self.phase_vector(model_training_input)\n",
    "\n",
    "        # Validation Data\n",
    "        model_valid_input, model_valid_output = self.validation_data()\n",
    "        valid_phase = self.phase_vector(model_valid_input)\n",
    "        return (model_training_input, model_training_output, training_phase,\n",
    "                model_valid_input, model_valid_output, valid_phase)\n",
    "\n",
    "    def get_model_training_xfc(self):\n",
    "        \"\"\"Build xfc from model training input\"\"\"\n",
    "        return self.build_xfc(self.model_training_input, self.num_memory_levels)\n",
    "    \n",
    "    def get_model_training_expected_output(self):\n",
    "        \"\"\"Find what the model should output for training data\"\"\"\n",
    "        return self.model_expected_output(self.model_training_output, self.training_phase)\n",
    "    \n",
    "    def get_valid_xfc(self):\n",
    "        \"\"\"Build xfc from model validation input\"\"\"\n",
    "        return self.build_xfc(self.model_valid_input, self.num_memory_levels)\n",
    "    \n",
    "    def get_model_valid_expected_output(self):\n",
    "        \"\"\"Find what the model should output for validation data\"\"\"\n",
    "        return self.model_expected_output(self.model_valid_output, self.valid_phase)\n",
    "    \n",
    "    def get_test_data(self):\n",
    "        \"\"\"Get test data after validation\"\"\"\n",
    "        num_validation_points = self.num_training_points \n",
    "        validation_end_index = self.num_training_points + num_validation_points\n",
    "        x_data = self.x[validation_end_index:]\n",
    "        y_data = self.y[validation_end_index:]\n",
    "        return x_data, y_data\n",
    "\n",
    "\n",
    "# Load data\n",
    "data = scipy.io.loadmat(\"PA_IO.mat\")\n",
    "x = data[\"x\"].squeeze()\n",
    "y = data[\"y\"].squeeze()\n",
    "\n",
    "# Create dataset object\n",
    "data_obj = dataset(x, y)\n",
    "\n",
    "# Access training data\n",
    "model_xfc = data_obj.get_model_training_xfc()\n",
    "model_training_expected_output = data_obj.get_model_training_expected_output()\n",
    "\n",
    "# Access validation data\n",
    "valid_xfc = data_obj.get_valid_xfc()\n",
    "model_valid_expected_output = data_obj.get_model_valid_expected_output()\n",
    "\n",
    "# Access test data\n",
    "x_data, y_data = data_obj.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba18ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63146409-0.11924996j  0.1694142 -0.01547961j -0.29918448+0.23918013j\n",
      "  1.27680917-1.02310172j -0.87359925+0.71303688j  0.12086561+0.23694819j\n",
      "  0.01362539+0.09275574j -0.09982292-0.22003663j  0.45094657+0.5524524j\n",
      " -0.35963882-0.32360673j -0.06705462-0.13809442j -0.02614158-0.01855645j\n",
      "  0.16654034-0.04988737j -0.48981135-0.01449885j  0.34387347+0.01718324j]\n"
     ]
    }
   ],
   "source": [
    "# Get Volterra Model of PA\n",
    "num_memory_levels = 3\n",
    "num_nl_orders = 5\n",
    "A = data_obj.volterra(num_nl_orders)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3184859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10/400  Loss=3.6815e+00\n",
      "Epoch  20/400  Loss=8.7692e-01\n",
      "Epoch  20/400  Loss=8.7692e-01\n",
      "Epoch  30/400  Loss=5.5562e-01\n",
      "Epoch  30/400  Loss=5.5562e-01\n",
      "Epoch  40/400  Loss=3.6344e-01\n",
      "Epoch  40/400  Loss=3.6344e-01\n",
      "Epoch  50/400  Loss=2.4845e-01\n",
      "Epoch  50/400  Loss=2.4845e-01\n",
      "Epoch  60/400  Loss=1.9311e-01\n",
      "Epoch  60/400  Loss=1.9311e-01\n",
      "Epoch  70/400  Loss=1.6399e-01\n",
      "Epoch  70/400  Loss=1.6399e-01\n",
      "Epoch  80/400  Loss=1.4414e-01\n",
      "Epoch  80/400  Loss=1.4414e-01\n",
      "Epoch  90/400  Loss=1.3115e-01\n",
      "Epoch  90/400  Loss=1.3115e-01\n",
      "Epoch 100/400  Loss=1.2224e-01\n",
      "Epoch 100/400  Loss=1.2224e-01\n",
      "Epoch 110/400  Loss=1.1700e-01\n",
      "Epoch 110/400  Loss=1.1700e-01\n",
      "Epoch 120/400  Loss=1.1420e-01\n",
      "Epoch 120/400  Loss=1.1420e-01\n",
      "Epoch 130/400  Loss=1.1159e-01\n",
      "Epoch 130/400  Loss=1.1159e-01\n",
      "Epoch 140/400  Loss=1.1289e-01\n",
      "Epoch 140/400  Loss=1.1289e-01\n",
      "Epoch 150/400  Loss=1.0968e-01\n",
      "Epoch 150/400  Loss=1.0968e-01\n",
      "Epoch 160/400  Loss=1.0839e-01\n",
      "Epoch 160/400  Loss=1.0839e-01\n",
      "Epoch 170/400  Loss=1.1050e-01\n",
      "Epoch 170/400  Loss=1.1050e-01\n",
      "Epoch 180/400  Loss=1.0864e-01\n",
      "Epoch 180/400  Loss=1.0864e-01\n",
      "Epoch 190/400  Loss=1.0732e-01\n",
      "Epoch 190/400  Loss=1.0732e-01\n",
      "Epoch 200/400  Loss=1.0997e-01\n",
      "Epoch 200/400  Loss=1.0997e-01\n",
      "Epoch 210/400  Loss=1.0976e-01\n",
      "Epoch 210/400  Loss=1.0976e-01\n",
      "Epoch 220/400  Loss=1.0662e-01\n",
      "Epoch 220/400  Loss=1.0662e-01\n",
      "Epoch 230/400  Loss=1.0906e-01\n",
      "Epoch 230/400  Loss=1.0906e-01\n",
      "Epoch 240/400  Loss=1.0755e-01\n",
      "Epoch 240/400  Loss=1.0755e-01\n",
      "Epoch 250/400  Loss=1.0882e-01\n",
      "Epoch 250/400  Loss=1.0882e-01\n",
      "Epoch 260/400  Loss=1.0563e-01\n",
      "Epoch 260/400  Loss=1.0563e-01\n",
      "Epoch 270/400  Loss=1.0624e-01\n",
      "Epoch 270/400  Loss=1.0624e-01\n",
      "Epoch 280/400  Loss=1.0720e-01\n",
      "Epoch 280/400  Loss=1.0720e-01\n",
      "Epoch 290/400  Loss=1.0669e-01\n",
      "Epoch 290/400  Loss=1.0669e-01\n",
      "Epoch 300/400  Loss=1.0517e-01\n",
      "Epoch 300/400  Loss=1.0517e-01\n",
      "Epoch 310/400  Loss=1.0413e-01\n",
      "Epoch 310/400  Loss=1.0413e-01\n",
      "Epoch 320/400  Loss=1.0363e-01\n",
      "Epoch 320/400  Loss=1.0363e-01\n",
      "Epoch 330/400  Loss=1.0416e-01\n",
      "Epoch 330/400  Loss=1.0416e-01\n",
      "Epoch 340/400  Loss=1.0450e-01\n",
      "Epoch 340/400  Loss=1.0450e-01\n",
      "Epoch 350/400  Loss=1.0025e-01\n",
      "Epoch 350/400  Loss=1.0025e-01\n",
      "Epoch 360/400  Loss=7.9045e-02\n",
      "Epoch 360/400  Loss=7.9045e-02\n",
      "Epoch 370/400  Loss=7.0972e-02\n",
      "Epoch 370/400  Loss=7.0972e-02\n",
      "Epoch 380/400  Loss=6.6293e-02\n",
      "Epoch 380/400  Loss=6.6293e-02\n",
      "Epoch 390/400  Loss=6.5289e-02\n",
      "Epoch 390/400  Loss=6.5289e-02\n",
      "Epoch 400/400  Loss=6.3747e-02\n",
      "-36.12787255094341\n",
      "Epoch 400/400  Loss=6.3747e-02\n",
      "-36.12787255094341\n"
     ]
    }
   ],
   "source": [
    "# Train NN on backprop PA for inv model\n",
    "\n",
    "class PNTDNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PNTDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, pntdnn):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.pntdnn = pntdnn\n",
    "        \n",
    "    def build_dataloaders(self, x , y):\n",
    "        X = torch.tensor(x, dtype=torch.float32)\n",
    "        Y = torch.tensor(y, dtype=torch.float32)\n",
    "        dataset = TensorDataset(X, Y)\n",
    "        loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "        return loader\n",
    "    \n",
    "    def train(self, train_loader, valid_loader, num_epochs=400, learning_rate=1e-3):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.pntdnn.parameters(), lr=learning_rate)\n",
    "        \n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.pntdnn.train()\n",
    "            running_train_loss = 0\n",
    "            running_valid_loss = 0\n",
    "            \n",
    "            for xb, yb in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                preds = self.pntdnn(xb)\n",
    "                loss = criterion(preds, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_train_loss += loss.item() * xb.size(0)\n",
    "                \n",
    "            train_loss = running_train_loss\n",
    "            \n",
    "            self.pntdnn.eval()\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in valid_loader:\n",
    "                    preds = self.pntdnn(xb)\n",
    "                    loss = criterion(preds, yb)\n",
    "                    running_valid_loss += loss.item() * xb.size(0)\n",
    "                \n",
    "            valid_loss = running_valid_loss\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            valid_losses.append(valid_loss)\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch + 1:3d}/{num_epochs}  Loss={train_loss:.4e}\")\n",
    "        \n",
    "        return train_losses, valid_losses\n",
    "\n",
    "    def prune_model(self, prune_amount=0.2):\n",
    "        pruned_model = copy.deepcopy(self.pntdnn)\n",
    "        parameters_to_prune = (\n",
    "            (pruned_model.fc1, 'weight'),\n",
    "            (pruned_model.fc2, 'weight'),\n",
    "        )\n",
    "        prune.global_unstructured(\n",
    "            parameters_to_prune,\n",
    "            pruning_method=prune.L1Unstructured,\n",
    "            amount=prune_amount,\n",
    "        )\n",
    "        return pruned_model\n",
    "    \n",
    "    def calculate_nmse(self, x, y):\n",
    "        \"\"\"Return NMSE in dB\"\"\"\n",
    "        self.pntdnn.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs = torch.tensor(x, dtype=torch.float32)\n",
    "            targets = torch.tensor(y, dtype=torch.float32)\n",
    "            outputs = self.pntdnn(inputs)\n",
    "            mse_loss = nn.MSELoss()(outputs, targets).item()\n",
    "            signal_power = torch.mean(targets ** 2).item()\n",
    "            nmse = mse_loss / signal_power\n",
    "            nmse = 10 * np.log10(nmse)\n",
    "        return nmse\n",
    "    \n",
    "\n",
    "# Instantiate and train the model\n",
    "input_size = model_xfc.shape[1]\n",
    "hidden_size = 12\n",
    "output_size = 2\n",
    "pntdnn = PNTDNN(input_size, hidden_size, output_size)\n",
    "nn_model = NN(pntdnn)\n",
    "train_loader = nn_model.build_dataloaders(model_xfc, model_training_expected_output)\n",
    "valid_loader = nn_model.build_dataloaders(valid_xfc, model_valid_expected_output)\n",
    "train_losses, valid_losses = nn_model.train(train_loader, valid_loader)\n",
    "print(nn_model.calculate_nmse(model_xfc, model_training_expected_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6554545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluation:\n",
    "    def __init__(self, x, y):\n",
    "        # Evalulate the performance of this model if this is the input and ouput data\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        print(self.find_ACLR())\n",
    "\n",
    "    def find_ACLR(self, fs = 800e6, bw_main_ch = 200e6, n_sub_ch = 10, nperseg = 2560):\n",
    "        \"\"\"Calculate the ACLR of the model for this dataset\"\"\"\n",
    "\n",
    "        #Find power spectral density of output\n",
    "        frequencies, psd = self.power_spectrum(self.y, fs=fs, nperseg=nperseg)\n",
    "        # Compute the left and right index of the main channel\n",
    "        index_left = np.min(np.where(frequencies>= -bw_main_ch/2))\n",
    "        index_right = np.max(np.where(frequencies<= bw_main_ch/2))\n",
    "\n",
    "        # Compute the length in index of each subchannel\n",
    "        sub_ch_index_len = int((index_right - index_left) / n_sub_ch)\n",
    "\n",
    "        # Compute the power of each subchannel and find the maximum power\n",
    "        sub_ch_power = np.zeros((n_sub_ch))\n",
    "        for c in range(n_sub_ch):\n",
    "            sub_ch_power[c] = np.sum(\n",
    "                psd[index_left + c * sub_ch_index_len:index_left + (c + 1) * sub_ch_index_len])\n",
    "        max_sub_ch_power = sub_ch_power.max()\n",
    "\n",
    "        # Compute ACLR for left and right adjacent channels\n",
    "        left_side_ch_power = np.sum(psd[index_left - sub_ch_index_len:index_left])\n",
    "        aclr_left = np.mean(10 * np.log10(left_side_ch_power / max_sub_ch_power))\n",
    "        right_side_channel_power = np.sum(psd[index_right:index_right + sub_ch_index_len])\n",
    "        aclr_right = np.mean(10 * np.log10(right_side_channel_power / max_sub_ch_power))\n",
    "\n",
    "        return aclr_left, aclr_right\n",
    "\n",
    "    def power_spectrum(self, complex_signal, fs=800e6, nperseg=2560):\n",
    "        \"\"\"Calculate power spectrum of complex signal\"\"\"\n",
    "        from scipy.signal import welch\n",
    "\n",
    "        f, Pxx = welch(complex_signal, fs=fs, nperseg=nperseg, return_onesided=False)\n",
    "        Pxx = np.fft.fftshift(Pxx)\n",
    "        f = np.fft.fftshift(f)\n",
    "        return f, Pxx\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
